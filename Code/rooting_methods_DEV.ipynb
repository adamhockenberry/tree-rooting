{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "The point of this notebook is to develop better tree rooting algorithms. Develop, because this will be messy for the time being and will eventually split into hopefully comprehensible code when the time arises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from Bio import Phylo\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "import ete3\n",
    "from io import StringIO\n",
    "import random\n",
    "from scipy.optimize import minimize, minimize_scalar\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Test my MP algorithm\n",
    "\n",
    "I'm confident that it works, at least on the trees I've tested. But I really need to demonstrate that here.\n",
    "\n",
    "Note that I've uncovered weird problems with the `root_at_midpoint()` method from `Bio.Phylo`, so I won't be trusting it as a positive control. Rather, should demonstrate that they are usually equivalent and when there are discrepancies my method produces the expected behavior (conserving branch length, for instance)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import rooting_methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for input_tree in glob.glob('../Tria_et_al_data/cyanobacteria/ingroup/phyml/*.nwk')[:]:\n",
    "    my_tree = Phylo.read(input_tree, 'newick', rooted=False)\n",
    "    initial_terminals = my_tree.get_terminals()\n",
    "    my_tree = rooting_methods.mp_root_adhock(my_tree)\n",
    "    assert my_tree.is_bifurcating()\n",
    "    my_bls = (my_tree.root.clades[0].branch_length, my_tree.root.clades[1].branch_length)\n",
    "    my_bls = sorted(my_bls)\n",
    "    phylo_tree = Phylo.read(input_tree, 'newick', rooted=False)\n",
    "    phylo_tree.root_at_midpoint()\n",
    "    phylo_bls = (phylo_tree.root.clades[0].branch_length, phylo_tree.root.clades[1].branch_length)\n",
    "    phylo_bls = sorted(phylo_bls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Investigate example errors**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The ete3 method is just plain wrong**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tree_loc = '../test.ete3.newick'\n",
    "# # tree_loc = '/Users/adamhockenberry/Projects/Phylogenetic_couplings/scratch/current/1AOE_A_rp75.newick'\n",
    "# tree = ete3.Tree(tree_loc)\n",
    "# outgroup = tree.get_midpoint_outgroup()\n",
    "# tree.set_outgroup(outgroup)\n",
    "# tree.render('%%inline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Add in a comparison to DendroPy to be comprehensive **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing method based off of minimizing the standard deviation in the distribution of root-to-tip distances\n",
    "\n",
    "...this is surprisingly easy and seems like it should work great...I guess it's just the Min-var or MCCV method as it's called in the MAD paper? Not sure if maximizing the likelihood of a gaussian is the sme as minimizing the coefficient of variation but I'm kind of guessing yes. And in any event this code is easily adapted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import rooting_methods\n",
    "import rooting_methods_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# tree = Phylo.read('../../Tree_rooting/Data/raw_OMA_trees/OMAGroup_479938.mafft.afa.treefile.Rooted.MPAJH', 'newick')\n",
    "# tree = Phylo.read('/Users/adamhockenberry/Downloads/BM_Folder/paper_tree.txt', 'newick')\n",
    "# rooted_tree.root_with_outgroup(['ELI', 'MAL'], outgroup_branch_length=10e-6)\n",
    "# tree = Phylo.read(StringIO('(((A:20, B:20):30,C:50):30, D:80)'), 'newick', rooted=False)\n",
    "# tree = Phylo.read('../../Tree_rooting/Data/euk_trees/KOG0001.faa.aln.nwk.Rooted.MADAJH', 'newick')\n",
    "tree = Phylo.read('../../Phylogenetic_couplings/Data/psicov150_aln_pdb/raw_trees/1a3aA.newick', 'newick')\n",
    "rooted_tree = rooting_methods.mp_root_adhock(tree)\n",
    "# Phylo.draw(rooted_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loops, best of 3: 12.6 s per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "a1, b1, c1 = rooting_methods.ml_root_adhock(rooted_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loops, best of 3: 2.09 s per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "a2, b2, c2 = rooting_methods_v2.mlfit_root_adhock(rooted_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing systematically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "id_species_dict = {}\n",
    "with open('../Tria_et_al_data/eukaryotes/ID_to_Species.txt', 'r') as infile:\n",
    "    texty = infile.readlines()\n",
    "    for line in texty[1:]:\n",
    "        sl = line.split('\\t')\n",
    "        id_species_dict[sl[0]] = sl[1]\n",
    "print(len(id_species_dict.keys()))\n",
    "\n",
    "species_seqid_dict = {}\n",
    "with open('../Tria_et_al_data/eukaryotes/cluster_to_seqid.txt', 'r') as infile:\n",
    "    texty = infile.readlines()\n",
    "    for line in texty:\n",
    "        sl = line.split('\\t')\n",
    "        if sl[0] == 'KOG0725':\n",
    "            species_seqid_dict[sl[1]] = sl[2].strip()\n",
    "print(len(species_seqid_dict.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# fungi = ['13684', ]\n",
    "# id_species_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** test monophyly **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def recursive_tree_monophyly(hypothetical_root, tree, test_set, is_mono):\n",
    "    if tree.is_monophyletic(test_set):\n",
    "        is_mono = True\n",
    "    if len(hypothetical_root.clades) == 2:\n",
    "        l_clade, r_clade = hypothetical_root.clades\n",
    "        if l_clade.branch_length > 0:\n",
    "            tree.root_with_outgroup(l_clade, outgroup_branch_length=10e-10)\n",
    "            is_mono = recursive_tree_monophyly(l_clade, tree, test_set, is_mono)\n",
    "            is_mono = recursive_tree_monophyly(r_clade, tree, test_set, is_mono)\n",
    "        elif r_clade.branch_length > 0:\n",
    "            tree.root_with_outgroup(r_clade, outgroup_branch_length=10e-10)\n",
    "            is_mono = recursive_tree_monophyly(l_clade, tree, test_set, is_mono)\n",
    "            is_mono = recursive_tree_monophyly(r_clade, tree, test_set, is_mono)\n",
    "    elif len(hypothetical_root.clades) == 1:\n",
    "        l_clade = hypothetical_root.clades[0]\n",
    "        if l_clade.branch_length > 0:\n",
    "            tree.root_with_outgroup(l_clade, outgroup_branch_length=10e-10)\n",
    "            is_mono = recursive_tree_monophyly(l_clade, tree, test_set, is_mono)\n",
    "    elif len(hypothetical_root.clades) == 0:\n",
    "        return is_mono\n",
    "    return is_mono\n",
    "\n",
    "# tree.get_terminals()\n",
    "# tree.is_monophyletic(metazoa)\n",
    "tree = Phylo.read('../test.ete3.newick', 'newick', rooted=False)\n",
    "tree = mp_root_adhock(tree)\n",
    "# tree.is_monophyletic([term for term in tree.get_terminals() if\\\n",
    "#                       term.name in ['7165', '7425', '7460', '121225', '7227', '6239']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testy = [term for term in tree.get_terminals() if\\\n",
    "                      term.name in metazoa]\n",
    "recursive_tree_monophyly(tree.root, tree, testy, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Phylo.draw(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "metazoa = ['10090', '121225', '9606', '30611', '8364', '7955', '8128', '8090',\\\n",
    "          '7668', '7460', '7425', '7227', '7165', '6239']\n",
    "problematic = ['../Tria_et_al_data/eukaryotes/ingroup/phyml/KOG3467.faa.aln.nwk',\\\n",
    "              '../Tria_et_al_data/eukaryotes/ingroup/phyml/KOG2866.faa.aln.nwk']\n",
    "\n",
    "trees_dir = '../Tria_et_al_data/eukaryotes/ingroup/phyml/*.nwk'\n",
    "ideal_species_number = 31\n",
    "\n",
    "# n_pruned = 15\n",
    "# trees_dir = '../Tria_et_al_data/eukaryotes/ingroup/phyml/*.{}.pruned'.format(n_pruned)\n",
    "# problematic = [i+'.{}.pruned'.format(n_pruned) for i in problematic]\n",
    "# # problematic += ['../Tria_et_al_data/eukaryotes/ingroup/phyml/KOG2688.faa.aln.nwk.6.pruned']\n",
    "# problematic += ['../Tria_et_al_data/eukaryotes/ingroup/phyml/KOG3887.faa.aln.nwk.15.pruned']\n",
    "# problematic += ['../Tria_et_al_data/eukaryotes/ingroup/phyml/KOG1374.faa.aln.nwk.15.pruned']\n",
    "# problematic += ['../Tria_et_al_data/eukaryotes/ingroup/phyml/KOG1558.faa.aln.nwk.15.pruned']\n",
    "# problematic += ['../Tria_et_al_data/eukaryotes/ingroup/phyml/KOG0284.faa.aln.nwk.15.pruned']\n",
    "# problematic += ['../Tria_et_al_data/eukaryotes/ingroup/phyml/KOG0594.faa.aln.nwk.15.pruned']\n",
    "# ideal_species_number = 31-n_pruned\n",
    "\n",
    "\n",
    "# trees_dir = ['../Tria_et_al_data/eukaryotes/ingroup/phyml/KOG0725.faa.aln.nwk']\n",
    "mp_success_rate = 0\n",
    "ml_success_rate = 0\n",
    "mad_success_rate = 0\n",
    "attempts = 0\n",
    "for tree_loc in glob.glob(trees_dir)[:50]:\n",
    "    if tree_loc in problematic:\n",
    "        continue\n",
    "    print('######## {}'.format(tree_loc))\n",
    "    tree = Phylo.read(tree_loc, 'newick')\n",
    "    if len(tree.get_terminals()) != ideal_species_number:\n",
    "        continue\n",
    "        \n",
    "    try:\n",
    "        mad_tree = Phylo.read(tree_loc+'.rooted', 'newick', rooted=True)\n",
    "    except ValueError:\n",
    "        print('MAD did not work here')\n",
    "        continue\n",
    "\n",
    "    testy = [term for term in tree.get_terminals() if\\\n",
    "                      term.name in metazoa]\n",
    "    rooted_tree = mp_root_adhock(tree)\n",
    "    valid = recursive_tree_monophyly(rooted_tree.root, rooted_tree, testy, False)\n",
    "    if valid:\n",
    "        attempts += 1\n",
    "        ###Mid point\n",
    "        mp_tree = mp_root_adhock(tree)\n",
    "        if set(testy) == set(mp_tree.root.clades[0].get_terminals()) or \\\n",
    "            set(testy) == set(mp_tree.root.clades[1].get_terminals()):\n",
    "                mp_success_rate += 1\n",
    "        ###ML        \n",
    "        ml_tree = max_likelihood_root(tree)\n",
    "        if set(testy) == set(ml_tree.root.clades[0].get_terminals()) or \\\n",
    "            set(testy) == set(ml_tree.root.clades[1].get_terminals()):\n",
    "                ml_success_rate += 1\n",
    "        ###MAD\n",
    "        testy = [term for term in mad_tree.get_terminals() if\\\n",
    "                      term.name in metazoa]\n",
    "        if set(testy) == set(mad_tree.root.clades[0].get_terminals()) or \\\n",
    "            set(testy) == set(mad_tree.root.clades[1].get_terminals()):\n",
    "                mad_success_rate += 1\n",
    "#     tree.root_at_midpoint()\n",
    "#     print(min([term.branch_length for term in tree.get_terminals()]))\n",
    "#     print(recursive_tree_monophyly(tree.root, tree, testy, False))\n",
    "    print(mp_success_rate, mad_success_rate)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mp_success_rate / attempts, ml_success_rate / attempts, mad_success_rate / attempts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Phylo.draw(tree)\n",
    "# Phylo.draw(mp_tree)\n",
    "# Phylo.draw(ml_tree)\n",
    "# Phylo.draw(mad_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mp_success_rate, ml_success_rate, mad_success_rate, attempts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tree_loc = '../Tria_et_al_data/eukaryotes/ingroup/phyml/KOG3467.faa.aln.nwk'\n",
    "tree = Phylo.read(tree_loc, 'newick')\n",
    "\n",
    "# tree.root_at_midpoint()\n",
    "tree = mp_root_adhock(tree)\n",
    "Phylo.draw(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# testy = [term for term in tree.get_terminals() if\\\n",
    "#                       term.name in metazoa]\n",
    "recursive_tree_monophyly(tree.root, tree, testy, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tree.get_terminals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A weighted MaxLik implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from Bio import Phylo\n",
    "import rooting_methods\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from scipy.optimize import minimize\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../Tree_weighting/Code/')\n",
    "import weighting_methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# def ml_root_weighted(tree):\n",
    "#     ###Depths are important! This is what I am trying to optimize in terms\n",
    "#     ###of making these look as close to normal as possible. So this gets the\n",
    "#     ###starting depths as a DataFrame and subsequent tree crawling adds/subtracts\n",
    "#     ###to these values\n",
    "#     initial_depths = tree.root.depths()\n",
    "#     terminal_depths_df = pd.DataFrame()\n",
    "#     terminal_depths_df['depth'] = np.nan\n",
    "#     for term in tree.get_terminals():\n",
    "#         terminal_depths_df.set_value(term.name, 'depth', initial_depths[term])\n",
    "#     depths_dict = {}\n",
    "#     depths_dict[tree.root] = terminal_depths_df\n",
    "    \n",
    "#     ###Getting starting weights\n",
    "#     weights_dict_single = weighting_methods.GSC_adhock_extended(tree)\n",
    "#     weights_dict_all = {}\n",
    "#     weights_dict_all[tree.root] = weights_dict_single\n",
    "\n",
    "#     explored, function_optima, depths_dict, weights_dict =\\\n",
    "#             recursive_crawl_ml(tree.root, [], [], depths_dict, weights_dict_all, tree)\n",
    "    \n",
    "#     ###Getting the best function eval and rooting there\n",
    "#     function_optima = sorted(function_optima, key=lambda x: x[1].fun)\n",
    "#     tree.root_with_outgroup(function_optima[0][0], outgroup_branch_length=0.)\n",
    "#     assert tree.root.clades[1].branch_length == 0.\n",
    "#     assert tree.root.clades[1] == function_optima[0][0]\n",
    "#     tree.root.clades[0].branch_length -= function_optima[0][1].x[0]\n",
    "#     tree.root.clades[1].branch_length += function_optima[0][1].x[0]\n",
    "#     return tree, function_optima, depths_dict, weights_dict\n",
    "\n",
    "# def recursive_crawl_ml(hypothetical_root, explored, function_optima, depths_dict, weights_dict, tree):\n",
    "#     if len(hypothetical_root.clades) == 2:\n",
    "#         l_clade, r_clade = hypothetical_root.clades\n",
    "#         l_bl = l_clade.branch_length\n",
    "#         r_bl = r_clade.branch_length\n",
    "#         #L clade first\n",
    "#         if l_bl > 0:\n",
    "#             depths_dict, downstream_terms, upstream_terms =\\\n",
    "#                     update_depth_df_dict(depths_dict, l_clade, hypothetical_root)\n",
    "#             weights_dict =\\\n",
    "#                     update_weights_dict(weights_dict, l_clade, hypothetical_root, downstream_terms, upstream_terms)\n",
    "#             res = optimize_root_loc_on_branch(l_clade, depths_dict[l_clade], weights_dict[l_clade], downstream_terms, upstream_terms)\n",
    "#             function_optima.append((l_clade, res))\n",
    "#             explored, function_optima, depths_dict, weights_dict =\\\n",
    "#                     recursive_crawl_ml(l_clade, explored, function_optima, depths_dict, weights_dict, tree)\n",
    "#         #R clade second\n",
    "#         if r_bl > 0:\n",
    "#             depths_dict, downstream_terms, upstream_terms =\\\n",
    "#                     update_depth_df_dict(depths_dict, r_clade, hypothetical_root)\n",
    "#             weights_dict =\\\n",
    "#                     update_weights_dict(weights_dict, r_clade, hypothetical_root, downstream_terms, upstream_terms)\n",
    "#             res = optimize_root_loc_on_branch(r_clade, depths_dict[r_clade], weights_dict[r_clade], downstream_terms, upstream_terms)\n",
    "#             function_optima.append((r_clade, res))\n",
    "#             explored, function_optima, depths_dict, weights_dict =\\\n",
    "#                     recursive_crawl_ml(r_clade, explored, function_optima, depths_dict, weights_dict, tree)\n",
    "#     elif len(hypothetical_root.clades) == 0:\n",
    "#         explored.append(hypothetical_root)\n",
    "#         return explored, function_optima, depths_dict, weights_dict\n",
    "    \n",
    "#     else:\n",
    "#         print('Some big error here with the number of clades stemming from this root')\n",
    "#     explored.append(hypothetical_root)\n",
    "#     return explored, function_optima, depths_dict, weights_dict\n",
    "\n",
    "# def update_depth_df_dict(depths_dict, my_clade, parent_clade):\n",
    "#     downstream_terms = [i.name for i in my_clade.get_terminals()]\n",
    "#     upstream_terms = list(set(list(depths_dict[parent_clade].index)) - set(downstream_terms))\n",
    "#     depths_dict[my_clade] = depths_dict[parent_clade].copy(deep=True)\n",
    "#     depths_dict[my_clade].loc[downstream_terms, 'depth'] -= my_clade.branch_length\n",
    "#     depths_dict[my_clade].loc[upstream_terms, 'depth'] += my_clade.branch_length\n",
    "#     return depths_dict, downstream_terms, upstream_terms\n",
    "\n",
    "# def update_weights_dict(weights_dict, my_clade, parent_clade, downstream_terms, upstream_terms):\n",
    "#     '''\n",
    "#     Some convoluted copy things happening here that should be double checked\n",
    "#     '''\n",
    "#     weights_dict[my_clade] = copy.copy(weights_dict[parent_clade])\n",
    "#     trashy = 0\n",
    "#     temp_ds = [next(tree.find_elements(term)) for term in downstream_terms]\n",
    "#     for term in temp_ds:\n",
    "#         trashy += weights_dict[my_clade][term][-1]\n",
    "#         weights_dict[my_clade][term] = weights_dict[my_clade][term][:-1]\n",
    "#     bl_to_disperse = my_clade.branch_length\n",
    "#     temp_us = [next(tree.find_elements(i)) for i in upstream_terms]\n",
    "#     to_divide = np.sum([weights_dict[my_clade][term][-1] for term in temp_us])\n",
    "#     for term in temp_us:\n",
    "#         weights_dict[my_clade][term] = weights_dict[my_clade][term] + [weights_dict[my_clade][term][-1] +\\\n",
    "#                                             weights_dict[my_clade][term][-1]/to_divide*bl_to_disperse]       \n",
    "#     return weights_dict\n",
    "\n",
    "# def optimize_root_loc_on_branch(my_clade, depths_df, weights_dict, downstream_terms, upstream_terms):\n",
    "#     '''\n",
    "#     '''    \n",
    "# #     print('####')\n",
    "\n",
    "\n",
    "#     downstream_dists = np.array(depths_df.loc[downstream_terms, 'depth'])\n",
    "#     downstream_weights = np.array([weights_dict[next(tree.find_elements(i))][-1] for i in downstream_terms])\n",
    "\n",
    "#     upstream_dists = np.array(depths_df.loc[upstream_terms, 'depth'])\n",
    "#     upstream_weights = np.array([weights_dict[next(tree.find_elements(i))][-1] for i in upstream_terms])\n",
    "#     old_upstream_weights = np.array([weights_dict[next(tree.find_elements(i))][-2] for i in upstream_terms])\n",
    "#     bl_bounds = np.array([[0., my_clade.branch_length]])\n",
    "#     ###Valid options for method are L-BFGS-B, SLSQP and TNC\n",
    "#     res = minimize(branch_scan_ml, np.array(np.mean(bl_bounds)),\\\n",
    "#                           args=(downstream_dists, upstream_dists,\\\n",
    "#                                 downstream_weights, upstream_weights, old_upstream_weights),\\\n",
    "#                           bounds=bl_bounds, method='SLSQP')\n",
    "# #     print(res)\n",
    "#     return res\n",
    "\n",
    "# def branch_scan_ml(modifier, ds_dists, us_dists, ds_weights, us_weights, old_us_weights):\n",
    "#     temp_ds_dists = ds_dists + modifier\n",
    "#     temp_us_dists = us_dists - modifier\n",
    "#     all_dists = np.concatenate((temp_ds_dists, temp_us_dists))\n",
    "    \n",
    "#     total_ds = np.sum(ds_weights)\n",
    "#     if total_ds != 0:\n",
    "#         temp_ds_weights = ds_weights + (ds_weights/total_ds*modifier)\n",
    "#     else:\n",
    "#         temp_ds_weights = ds_weights + modifier\n",
    "\n",
    "\n",
    "#     total_us = np.sum(old_us_weights)\n",
    "#     if total_us != 0:\n",
    "#         temp_us_weights = us_weights - (old_us_weights/total_us*modifier)\n",
    "#     else:\n",
    "#         temp_us_weights = us_weights - modifier\n",
    "# #     all_weights = np.array([1 for i in range(all_dists.shape[0])])\n",
    "#     all_weights = np.concatenate((temp_ds_weights, temp_us_weights))\n",
    "# #     print(all_weights)\n",
    "#     dsw = DescrStatsW(all_dists, all_weights)\n",
    "#     return dsw.std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import rooting_methods_weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# tree = Phylo.read('../../Phylogenetic_couplings/Data/psicov150_aln_pdb/raw_trees/1a3aA.newick', 'newick')\n",
    "tree = Phylo.read('/Users/adamhockenberry/Downloads/BM_Folder/paper_tree.txt', 'newick')\n",
    "# tree = Phylo.read(StringIO('(((A:20, B:20):30,C:50):30, D:80)'), 'newick', rooted=False)\n",
    "# tree = Phylo.read('../../Tree_rooting/Tria_et_al_data/eukaryotes/ingroup/phyml/KOG0007.faa.aln.nwk', 'newick')\n",
    "# Phylo.draw(tree)\n",
    "# tree.root_with_outgroup('A', outgroup_branch_length=10e-8)\n",
    "# C = next(tree.find_elements('C'))\n",
    "# C.branch_length = 40\n",
    "tree.root_with_outgroup('MAL')\n",
    "# noi = next(tree.find_elements('PV22'))\n",
    "# noi.branch_length += 20\n",
    "# Phylo.draw(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tree = rooting_methods.mp_root_adhock(tree)\n",
    "Phylo.draw(tree)\n",
    "print([(i.name, i.branch_length) for i in tree.root.clades])\n",
    "tree, a, b, c = rooting_methods_weighted.ml_root_weighted(tree)\n",
    "Phylo.draw(tree)\n",
    "print([(i.name, i.branch_length) for i in tree.root.clades])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%timeit\n",
    "ml_root_weighted(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(tree.root.clades[1].get_terminals())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for key,val in c.items():\n",
    "    print('#####')\n",
    "    print(key)\n",
    "    print(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# tree = Phylo.read('../../Tree_rooting/Tria_et_al_data/eukaryotes/ingroup/phyml/KOG0007.faa.aln.nwk', 'newick')\n",
    "# tree = rooting_methods.mp_root_adhock(tree)\n",
    "# Phylo.draw(tree)\n",
    "tree,a,b = rooting_methods.ml_root_adhock(tree)\n",
    "Phylo.draw(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print([(i.name, i.branch_length) for i in tree.root.clades])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testy = [val for key, val in tree.depths().items() if key in tree.get_terminals()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(np.std(testy), np.mean(testy), np.std(testy)/np.mean(testy))\n",
    "print(-np.sum(stats.norm.logpdf(testy, loc=np.mean(testy), scale=np.std(testy))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(np.std(testy), np.mean(testy), np.std(testy)/np.mean(testy))\n",
    "print(-np.sum(stats.norm.logpdf(testy, loc=np.mean(testy), scale=np.std(testy))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(np.std(testy), np.mean(testy), np.std(testy)/np.mean(testy))\n",
    "print(-np.sum(stats.norm.logpdf(testy, loc=np.mean(testy), scale=np.std(testy))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from statsmodels.stats.weightstats import DescrStatsW\n",
    "arr = np.arange(-5, 5)\n",
    "weights = np.arange(9, -1, -1)  # Same size as arr\n",
    "print(arr, weights)\n",
    "dsw = DescrStatsW(arr, weights)\n",
    "cv = dsw.std / abs(dsw.mean)  # weighted std / abs of weighted mean\n",
    "print(cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sm.stats.DescrStatsW.mean()\n",
    "\n",
    "from statsmodels.stats.weightstats import DescrStatsW\n",
    "\n",
    "cv = dsw.std / abs(dsw.mean)  # weighted std / abs of weighted mean\n",
    "\n",
    "print(cv)\n",
    "1.6583123951777001\n",
    "\n",
    "\n",
    "\n",
    "weighted_stats = DescrStatsW(array, weights=weights, ddof=0)\n",
    ">>> weighted_stats.std       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, )\n",
    "ax.plot(testy.support, testy.density)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A weighted MAD... ugh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import rooting_methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mad_root_weighted(tree):\n",
    "    for node in tree.get_terminals() + tree.get_nonterminals():\n",
    "        if node == tree.root:\n",
    "            continue\n",
    "        if node.branch_length == 0.:\n",
    "            node.branch_length = 10e-16\n",
    "    dist_df = get_lca_dist_df(tree)\n",
    "    tempy_dict = {}\n",
    "    tempy_dict[tree.root] = dist_df\n",
    "    explored, function_optima, lca_dist_df_dict = recursive_crawl_mad(tree.root, [], [], tree, tempy_dict)\n",
    "    function_optima = sorted(function_optima, key=lambda x: x[1][1])\n",
    "    tree.root_with_outgroup(function_optima[0][0], outgroup_branch_length=0.)\n",
    "    tree.root.clades[0].branch_length -= function_optima[0][1][0]\n",
    "    tree.root.clades[1].branch_length += function_optima[0][1][0]\n",
    "    RAI = function_optima[0][1][1] / function_optima[1][1][1]\n",
    "    return tree, RAI, function_optima\n",
    "\n",
    "\n",
    "def get_lca_dist_df(tree):\n",
    "    ''' \n",
    "    Where distance matrix here is subtle. I'm actually calculating the distance to LCA for an initial \n",
    "    hypothetical bifurcating root.\n",
    "    '''\n",
    "    assert tree.is_bifurcating()\n",
    "    initial = np.zeros((len(tree.get_terminals()),len(tree.get_terminals())))\n",
    "    #Call recursive function\n",
    "    recurse, finished_list = recursive_clade(initial, tree.root, finished=[])\n",
    "    final = recurse - recurse.diagonal()\n",
    "    term_names = [i.name for i in tree.get_terminals()]\n",
    "    final_df = pd.DataFrame(final, index=term_names, columns=term_names)\n",
    "    return final_df\n",
    "\n",
    "def recursive_clade(vcv_matrix, initial_clade, finished=[]):\n",
    "    ''' \n",
    "    This is kind of complicated looking but it should scale linearly with tree size\n",
    "    '''\n",
    "    if len(initial_clade) == 2:\n",
    "        #Add branch length to relevant cells in matrix and move down the left side\n",
    "        if not set(initial_clade[0].get_terminals()).issubset(set(finished)):\n",
    "            clade = initial_clade[0]\n",
    "            clade_term_n = len(clade.get_terminals())\n",
    "            finished_n = len(finished)\n",
    "            vcv_matrix[finished_n:finished_n+clade_term_n, finished_n:finished_n+clade_term_n] += clade.branch_length\n",
    "            vcv_matrix, finished = recursive_clade(vcv_matrix, clade, finished)\n",
    "        #Add branch length to relevant cells in matrix and move down the right side\n",
    "        if not set(initial_clade[1].get_terminals()).issubset(set(finished)):\n",
    "            clade = initial_clade[1]\n",
    "            clade_term_n = len(clade.get_terminals())\n",
    "            finished_n = len(finished)\n",
    "            vcv_matrix[finished_n:finished_n+clade_term_n, finished_n:finished_n+clade_term_n] += clade.branch_length\n",
    "            vcv_matrix, finished = recursive_clade(vcv_matrix, clade, finished)\n",
    "    elif len(initial_clade) == 0:\n",
    "        finished.append(initial_clade)\n",
    "    else:\n",
    "        print(\"ERROR: APPEARS TO BE A NON-BINARY TREE. MATRIX GENERATION WILL PROBABLY FAIL\")\n",
    "    return vcv_matrix, finished\n",
    "\n",
    "def recursive_crawl_mad(hypothetical_root, explored, function_optima, tree, lca_dist_df_dict):\n",
    "    if len(hypothetical_root.clades) == 2:\n",
    "        l_clade, r_clade = hypothetical_root.clades\n",
    "        ###Recurse on l clade\n",
    "        lca_dist_df_dict, my_terms, other_terms = update_lca_dist_df_dict(lca_dist_df_dict, l_clade, hypothetical_root, tree)\n",
    "        res = mad_from_df(l_clade, my_terms, other_terms, lca_dist_df_dict[l_clade])\n",
    "        function_optima.append((l_clade, res))\n",
    "        explored, function_optima, lca_dist_df_dict = recursive_crawl_mad(l_clade, explored, function_optima, tree, lca_dist_df_dict)\n",
    "        ###Recurse on r clade\n",
    "        lca_dist_df_dict, my_terms, other_terms = update_lca_dist_df_dict(lca_dist_df_dict, r_clade, hypothetical_root, tree)\n",
    "        res = mad_from_df(r_clade, my_terms, other_terms, lca_dist_df_dict[r_clade])\n",
    "        function_optima.append((r_clade, res))\n",
    "        explored, function_optima, lca_dist_df_dict = recursive_crawl_mad(r_clade, explored, function_optima, tree, lca_dist_df_dict)\n",
    "    elif len(hypothetical_root.clades) == 0:\n",
    "        explored.append(hypothetical_root)\n",
    "        return explored, function_optima, lca_dist_df_dict\n",
    "    else:\n",
    "        print('non binary tree...?')\n",
    "    explored.append(hypothetical_root)\n",
    "    return explored, function_optima, lca_dist_df_dict\n",
    "\n",
    "def update_lca_dist_df_dict(lca_dist_df_dict, my_clade, parent, my_tree):\n",
    "    bl = my_clade.branch_length\n",
    "    downstream_terms = [i.name for i in my_clade.get_terminals()]\n",
    "    upstream_terms = list(set([i.name for i in my_tree.get_terminals()]) - set(downstream_terms))\n",
    "    lca_dist_df = lca_dist_df_dict[parent].copy(deep=True)\n",
    "    lca_dist_df.loc[downstream_terms,upstream_terms] -= bl\n",
    "    lca_dist_df.loc[upstream_terms,downstream_terms] += bl\n",
    "    lca_dist_df_dict[my_clade] = lca_dist_df\n",
    "    return lca_dist_df_dict, downstream_terms, upstream_terms\n",
    "\n",
    "def mad_from_df(my_clade, my_terms, other_terms, lca_dist_df):\n",
    "    '''\n",
    "    Need to document this\n",
    "    '''\n",
    "    print('###########')\n",
    "    my_df = lca_dist_df.loc[my_terms, my_terms]\n",
    "    other_df = lca_dist_df.loc[other_terms, other_terms]\n",
    "    my_df_trans = my_df.T\n",
    "    other_df_trans = other_df.T\n",
    "    print(my_df_trans)\n",
    "    print(other_df_trans)\n",
    "    #Dealing with same side pairs\n",
    "    ss_a_dists = np.abs(np.concatenate((my_df.values[np.triu_indices(len(my_terms), k = 1)],\\\n",
    "                                other_df.values[np.triu_indices(len(other_terms), k = 1)])))\n",
    "    ss_b_dists = np.abs(np.concatenate((my_df_trans.values[np.triu_indices(len(my_terms), k = 1)],\\\n",
    "                                other_df_trans.values[np.triu_indices(len(other_terms), k = 1)])))\n",
    "    print(ss_a_dists, ss_b_dists)\n",
    "    ss_total_dists = ss_a_dists + ss_b_dists\n",
    "    ss_devs = np.abs(((2*ss_a_dists)/ss_total_dists)-1)\n",
    "    print(ss_devs)\n",
    "    #Dealing with different side pairs\n",
    "    ds_a_dists = lca_dist_df.loc[my_terms, other_terms].values.flatten(order='C')\n",
    "    ds_b_dists = lca_dist_df.loc[other_terms, my_terms].values.flatten(order='F')\n",
    "    ds_total_dists = ds_a_dists + ds_b_dists\n",
    "\n",
    "    ###Using the analytical solution to \"rho\" parameter as outlined in the MAD paper\n",
    "    total_bl = my_clade.branch_length\n",
    "    if total_bl > 0.:\n",
    "        rho = np.sum((ds_total_dists-(2*ds_a_dists))*ds_total_dists**-2)/(2*total_bl*np.sum(ds_total_dists**-2))\n",
    "        modifier = total_bl*rho\n",
    "        modifier = min(max(0, modifier), total_bl)\n",
    "    else:\n",
    "        modifier = 0.\n",
    "\n",
    "    ###Rescale the distances with the optimized modifier\n",
    "    ds_a_dists = ds_a_dists + modifier\n",
    "    ds_b_dists = ds_b_dists - modifier\n",
    "    ds_total_dists = ds_a_dists + ds_b_dists\n",
    "    ###Calculate their deviations\n",
    "    ds_devs = np.abs(((2*ds_a_dists)/ds_total_dists)-1)\n",
    "\n",
    "    ###Concatenate them with the pre-computed same side deviations (ss_devs)\n",
    "    all_devs = np.concatenate((ss_devs, ds_devs))\n",
    "    ###And compute final MAD score\n",
    "    all_devs = all_devs**2\n",
    "    dev_score = np.mean(all_devs)\n",
    "    dev_score = dev_score**0.5\n",
    "    return (modifier, dev_score)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# tree = Phylo.read('../../Phylogenetic_couplings/Data/psicov150_aln_pdb/raw_trees/1a3aA.newick', 'newick')\n",
    "# tree = Phylo.read('/Users/adamhockenberry/Downloads/BM_Folder/paper_tree.txt', 'newick')\n",
    "tree = Phylo.read(StringIO('(((A:20, B:20):30,C:50):30, D:80)'), 'newick', rooted=False)\n",
    "# tree = Phylo.read('../../Tree_rooting/Tria_et_al_data/eukaryotes/ingroup/phyml/KOG0007.faa.aln.nwk', 'newick')\n",
    "# Phylo.draw(tree)\n",
    "# tree.root_with_outgroup('A', outgroup_branch_length=10e-8)\n",
    "# C = next(tree.find_elements('C'))\n",
    "# C.branch_length = 40\n",
    "# tree.root_with_outgroup('MAL')\n",
    "# noi = next(tree.find_elements('PV22'))\n",
    "# noi.branch_length += 20\n",
    "# Phylo.draw(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tree = rooting_methods.mp_root_adhock(tree)\n",
    "Phylo.draw(tree)\n",
    "print([(i.name, i.branch_length) for i in tree.root.clades])\n",
    "tree, a, b = mad_root_weighted(tree)\n",
    "# Phylo.draw(tree)\n",
    "# print([(i.name, i.branch_length) for i in tree.root.clades])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tree.depths()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i, terminal_a in enumerate(tree.get_terminals()):\n",
    "    for j, terminal_b in enumerate(tree.get_terminals()):\n",
    "        if j >= i:\n",
    "            continue\n",
    "        path = [terminal_a] + tree.trace(terminal_a, terminal_b)\n",
    "        ca = tree.common_ancestor(terminal_a, terminal_b)\n",
    "        if ca.branch_length:\n",
    "            path_len = np.sum([edge.branch_length for edge in path if edge.branch_length]) - ca.branch_length\n",
    "        else: \n",
    "            path_len = np.sum([edge.branch_length for edge in path if edge.branch_length])\n",
    "        print(terminal_a, terminal_b, path_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testy = get_lca_dist_df(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_paths = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(index=['AB', 'AC', 'AD', 'BC', 'BD', 'CD'],\\\n",
    "                  columns=['AB', 'AC', 'AD', 'BC', 'BD', 'CD'], dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in df.index:\n",
    "    df.set_value(i, i, 1.)\n",
    "pairs = [['AB', 'AC', 0.1],\\\n",
    "         ['AB', 'AD', 0.0625],\\\n",
    "         ['AB', 'BC', 0.1],\\\n",
    "         ['AB', 'BD', 0.0625],\\\n",
    "         ['AB', 'CD', 0.],\\\n",
    "         ['AC', 'AD', 0.15625],\\\n",
    "         ['AC', 'BC', 0.64],\\\n",
    "         ['AC', 'BD', 0.05625],\\\n",
    "         ['AC', 'CD', 0.15625],\\\n",
    "         ['AD', 'BC', 0.05625],\\\n",
    "         ['AD', 'BD', 0.765625],\\\n",
    "         ['AD', 'CD', 0.47265625],\\\n",
    "         ['BC', 'BD', 0.15625],\\\n",
    "         ['BC', 'CD', 0.15625],\\\n",
    "         ['BD', 'CD', 0.47265625]]\n",
    "for i,j,k in pairs:\n",
    "    df.set_value(i, j, k)\n",
    "    df.set_value(j, i, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mat = df.values\n",
    "inv_mat = np.linalg.inv(mat)\n",
    "rowsums = np.sum(inv_mat, axis=1)\n",
    "weights = rowsums/inv_mat.sum()\n",
    "weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.matshow(inv_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(np.array([40, 100, 160, 50, 160, 160])/230)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Toy example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(index=['AB', 'AC', 'BC'],\\\n",
    "                  columns=['AB', 'AC', 'BC'], dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in df.index:\n",
    "    df.set_value(i, i, 1.)\n",
    "pairs = [['AB', 'AC', (20**2)/(40*100)],\\\n",
    "         ['AB', 'BC', (20**2)/(40*100)],\\\n",
    "         ['AC', 'BC', (80**2)/(100*100)]]\n",
    "for i,j,k in pairs:\n",
    "    df.set_value(i, j, k)\n",
    "    df.set_value(j, i, k)\n",
    "\n",
    "mat = df.values\n",
    "inv_mat = np.linalg.inv(mat)\n",
    "rowsums = np.sum(inv_mat, axis=1)\n",
    "weights = rowsums/inv_mat.sum()\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in df.index:\n",
    "    df.set_value(i, i, 1.)\n",
    "pairs = [['AB', 'AC', (5**2)/(10*100)],\\\n",
    "         ['AB', 'BC', (5**2)/(10*100)],\\\n",
    "         ['AC', 'BC', (95**2)/(100*100)]]\n",
    "for i,j,k in pairs:\n",
    "    df.set_value(i, j, k)\n",
    "    df.set_value(j, i, k)\n",
    "\n",
    "mat = df.values\n",
    "inv_mat = np.linalg.inv(mat)\n",
    "rowsums = np.sum(inv_mat, axis=1)\n",
    "weights = rowsums/inv_mat.sum()\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "20**2 / 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "1/((1/50.) + (1/((50*130)/180)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "1/((1/130.)+(1/20)+(1/((50*130)/180)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "20.967741935483872 / (20.967741935483872+11.711711711711711+11.711711711711711)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "112.5/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mat = [[50, 30, 0],\\\n",
    "       [30, 50, 0],\\\n",
    "       [0, 0, 50]]\n",
    "inv_mat = np.linalg.inv(mat)\n",
    "rowsums = np.sum(inv_mat, axis=1)\n",
    "weights = rowsums/inv_mat.sum()\n",
    "weights, np.sum(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(36.111111+50)/(36.111111+130+40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "50/102.6315"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mat = [[50, 45, 0],\\\n",
    "       [45, 50, 0],\\\n",
    "       [0, 0, 50]]\n",
    "inv_mat = np.linalg.inv(mat)\n",
    "rowsums = np.sum(inv_mat, axis=1)\n",
    "weights = rowsums/inv_mat.sum()\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mat = [[80, 60, 30, 0],\\\n",
    "       [60, 80, 30, 0],\\\n",
    "       [30, 30, 80, 0],\\\n",
    "       [0, 0, 0, 80]]\n",
    "inv_mat = np.linalg.inv(mat)\n",
    "rowsums = np.sum(inv_mat, axis=1)\n",
    "weights = rowsums/inv_mat.sum()\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "20/(110/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "40/(200/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
