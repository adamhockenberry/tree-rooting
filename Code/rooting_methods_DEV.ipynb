{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "The point of this notebook is to develop better tree rooting algorithms. Develop, because this will be messy for the time being and will eventually split into hopefully comprehensible code when the time arises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from Bio import Phylo, SeqIO\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "import ete3\n",
    "from io import StringIO\n",
    "import random\n",
    "from scipy.optimize import minimize, minimize_scalar\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Test my MP algorithm\n",
    "\n",
    "I'm confident that it works, at least on the trees I've tested. But I really need to demonstrate that here.\n",
    "\n",
    "Note that I've uncovered weird problems with the `root_at_midpoint()` method from `Bio.Phylo`, so I won't be trusting it as a positive control. Rather, should demonstrate that they are usually equivalent and when there are discrepancies my method produces the expected behavior (conserving branch length, for instance)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import rooting_methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for input_tree in glob.glob('../Tria_et_al_data/cyanobacteria/ingroup/phyml/*.nwk')[:]:\n",
    "    my_tree = Phylo.read(input_tree, 'newick', rooted=False)\n",
    "    initial_terminals = my_tree.get_terminals()\n",
    "    my_tree = rooting_methods.mp_root_adhock(my_tree)\n",
    "    assert my_tree.is_bifurcating()\n",
    "    my_bls = (my_tree.root.clades[0].branch_length, my_tree.root.clades[1].branch_length)\n",
    "    my_bls = sorted(my_bls)\n",
    "    phylo_tree = Phylo.read(input_tree, 'newick', rooted=False)\n",
    "    phylo_tree.root_at_midpoint()\n",
    "    phylo_bls = (phylo_tree.root.clades[0].branch_length, phylo_tree.root.clades[1].branch_length)\n",
    "    phylo_bls = sorted(phylo_bls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Investigate example errors**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The ete3 method is just plain wrong**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tree_loc = '../test.ete3.newick'\n",
    "# # tree_loc = '/Users/adamhockenberry/Projects/Phylogenetic_couplings/scratch/current/1AOE_A_rp75.newick'\n",
    "# tree = ete3.Tree(tree_loc)\n",
    "# outgroup = tree.get_midpoint_outgroup()\n",
    "# tree.set_outgroup(outgroup)\n",
    "# tree.render('%%inline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Add in a comparison to DendroPy to be comprehensive **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing method based off of minimizing the standard deviation in the distribution of root-to-tip distances\n",
    "\n",
    "...this is surprisingly easy and seems like it should work great...I guess it's just the Min-var or MCCV method as it's called in the MAD paper? Not sure if maximizing the likelihood of a gaussian is the sme as minimizing the coefficient of variation but I'm kind of guessing yes. And in any event this code is easily adapted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import rooting_methods\n",
    "import rooting_methods_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# tree = Phylo.read('../../Tree_rooting/Data/raw_OMA_trees/OMAGroup_479938.mafft.afa.treefile.Rooted.MPAJH', 'newick')\n",
    "# tree = Phylo.read('/Users/adamhockenberry/Downloads/BM_Folder/paper_tree.txt', 'newick')\n",
    "# rooted_tree.root_with_outgroup(['ELI', 'MAL'], outgroup_branch_length=10e-6)\n",
    "# tree = Phylo.read(StringIO('(((A:20, B:20):30,C:50):30, D:80)'), 'newick', rooted=False)\n",
    "# tree = Phylo.read('../../Tree_rooting/Data/euk_trees/KOG0001.faa.aln.nwk.Rooted.MADAJH', 'newick')\n",
    "tree = Phylo.read('../../Phylogenetic_couplings/Data/psicov150_aln_pdb/raw_trees/1a3aA.newick', 'newick')\n",
    "rooted_tree = rooting_methods.mp_root_adhock(tree)\n",
    "# Phylo.draw(rooted_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%timeit\n",
    "a1, b1, c1 = rooting_methods.ml_root_adhock(rooted_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%timeit\n",
    "a2, b2, c2 = rooting_methods_v2.mlfit_root_adhock(rooted_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing systematically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "id_species_dict = {}\n",
    "with open('../Tria_et_al_data/eukaryotes/ID_to_Species.txt', 'r') as infile:\n",
    "    texty = infile.readlines()\n",
    "    for line in texty[1:]:\n",
    "        sl = line.split('\\t')\n",
    "        id_species_dict[sl[0]] = sl[1]\n",
    "print(len(id_species_dict.keys()))\n",
    "\n",
    "species_seqid_dict = {}\n",
    "with open('../Tria_et_al_data/eukaryotes/cluster_to_seqid.txt', 'r') as infile:\n",
    "    texty = infile.readlines()\n",
    "    for line in texty:\n",
    "        sl = line.split('\\t')\n",
    "        if sl[0] == 'KOG0725':\n",
    "            species_seqid_dict[sl[1]] = sl[2].strip()\n",
    "print(len(species_seqid_dict.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# fungi = ['13684', ]\n",
    "# id_species_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** test monophyly **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def recursive_tree_monophyly(hypothetical_root, tree, test_set, is_mono):\n",
    "    if tree.is_monophyletic(test_set):\n",
    "        is_mono = True\n",
    "    if len(hypothetical_root.clades) == 2:\n",
    "        l_clade, r_clade = hypothetical_root.clades\n",
    "        if l_clade.branch_length > 0:\n",
    "            tree.root_with_outgroup(l_clade, outgroup_branch_length=10e-10)\n",
    "            is_mono = recursive_tree_monophyly(l_clade, tree, test_set, is_mono)\n",
    "            is_mono = recursive_tree_monophyly(r_clade, tree, test_set, is_mono)\n",
    "        elif r_clade.branch_length > 0:\n",
    "            tree.root_with_outgroup(r_clade, outgroup_branch_length=10e-10)\n",
    "            is_mono = recursive_tree_monophyly(l_clade, tree, test_set, is_mono)\n",
    "            is_mono = recursive_tree_monophyly(r_clade, tree, test_set, is_mono)\n",
    "    elif len(hypothetical_root.clades) == 1:\n",
    "        l_clade = hypothetical_root.clades[0]\n",
    "        if l_clade.branch_length > 0:\n",
    "            tree.root_with_outgroup(l_clade, outgroup_branch_length=10e-10)\n",
    "            is_mono = recursive_tree_monophyly(l_clade, tree, test_set, is_mono)\n",
    "    elif len(hypothetical_root.clades) == 0:\n",
    "        return is_mono\n",
    "    return is_mono\n",
    "\n",
    "# tree.get_terminals()\n",
    "# tree.is_monophyletic(metazoa)\n",
    "tree = Phylo.read('../test.ete3.newick', 'newick', rooted=False)\n",
    "tree = mp_root_adhock(tree)\n",
    "# tree.is_monophyletic([term for term in tree.get_terminals() if\\\n",
    "#                       term.name in ['7165', '7425', '7460', '121225', '7227', '6239']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testy = [term for term in tree.get_terminals() if\\\n",
    "                      term.name in metazoa]\n",
    "recursive_tree_monophyly(tree.root, tree, testy, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Phylo.draw(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "metazoa = ['10090', '121225', '9606', '30611', '8364', '7955', '8128', '8090',\\\n",
    "          '7668', '7460', '7425', '7227', '7165', '6239']\n",
    "problematic = ['../Tria_et_al_data/eukaryotes/ingroup/phyml/KOG3467.faa.aln.nwk',\\\n",
    "              '../Tria_et_al_data/eukaryotes/ingroup/phyml/KOG2866.faa.aln.nwk']\n",
    "\n",
    "trees_dir = '../Tria_et_al_data/eukaryotes/ingroup/phyml/*.nwk'\n",
    "ideal_species_number = 31\n",
    "\n",
    "# n_pruned = 15\n",
    "# trees_dir = '../Tria_et_al_data/eukaryotes/ingroup/phyml/*.{}.pruned'.format(n_pruned)\n",
    "# problematic = [i+'.{}.pruned'.format(n_pruned) for i in problematic]\n",
    "# # problematic += ['../Tria_et_al_data/eukaryotes/ingroup/phyml/KOG2688.faa.aln.nwk.6.pruned']\n",
    "# problematic += ['../Tria_et_al_data/eukaryotes/ingroup/phyml/KOG3887.faa.aln.nwk.15.pruned']\n",
    "# problematic += ['../Tria_et_al_data/eukaryotes/ingroup/phyml/KOG1374.faa.aln.nwk.15.pruned']\n",
    "# problematic += ['../Tria_et_al_data/eukaryotes/ingroup/phyml/KOG1558.faa.aln.nwk.15.pruned']\n",
    "# problematic += ['../Tria_et_al_data/eukaryotes/ingroup/phyml/KOG0284.faa.aln.nwk.15.pruned']\n",
    "# problematic += ['../Tria_et_al_data/eukaryotes/ingroup/phyml/KOG0594.faa.aln.nwk.15.pruned']\n",
    "# ideal_species_number = 31-n_pruned\n",
    "\n",
    "\n",
    "# trees_dir = ['../Tria_et_al_data/eukaryotes/ingroup/phyml/KOG0725.faa.aln.nwk']\n",
    "mp_success_rate = 0\n",
    "ml_success_rate = 0\n",
    "mad_success_rate = 0\n",
    "attempts = 0\n",
    "for tree_loc in glob.glob(trees_dir)[:50]:\n",
    "    if tree_loc in problematic:\n",
    "        continue\n",
    "    print('######## {}'.format(tree_loc))\n",
    "    tree = Phylo.read(tree_loc, 'newick')\n",
    "    if len(tree.get_terminals()) != ideal_species_number:\n",
    "        continue\n",
    "        \n",
    "    try:\n",
    "        mad_tree = Phylo.read(tree_loc+'.rooted', 'newick', rooted=True)\n",
    "    except ValueError:\n",
    "        print('MAD did not work here')\n",
    "        continue\n",
    "\n",
    "    testy = [term for term in tree.get_terminals() if\\\n",
    "                      term.name in metazoa]\n",
    "    rooted_tree = mp_root_adhock(tree)\n",
    "    valid = recursive_tree_monophyly(rooted_tree.root, rooted_tree, testy, False)\n",
    "    if valid:\n",
    "        attempts += 1\n",
    "        ###Mid point\n",
    "        mp_tree = mp_root_adhock(tree)\n",
    "        if set(testy) == set(mp_tree.root.clades[0].get_terminals()) or \\\n",
    "            set(testy) == set(mp_tree.root.clades[1].get_terminals()):\n",
    "                mp_success_rate += 1\n",
    "        ###ML        \n",
    "        ml_tree = max_likelihood_root(tree)\n",
    "        if set(testy) == set(ml_tree.root.clades[0].get_terminals()) or \\\n",
    "            set(testy) == set(ml_tree.root.clades[1].get_terminals()):\n",
    "                ml_success_rate += 1\n",
    "        ###MAD\n",
    "        testy = [term for term in mad_tree.get_terminals() if\\\n",
    "                      term.name in metazoa]\n",
    "        if set(testy) == set(mad_tree.root.clades[0].get_terminals()) or \\\n",
    "            set(testy) == set(mad_tree.root.clades[1].get_terminals()):\n",
    "                mad_success_rate += 1\n",
    "#     tree.root_at_midpoint()\n",
    "#     print(min([term.branch_length for term in tree.get_terminals()]))\n",
    "#     print(recursive_tree_monophyly(tree.root, tree, testy, False))\n",
    "    print(mp_success_rate, mad_success_rate)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mp_success_rate / attempts, ml_success_rate / attempts, mad_success_rate / attempts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Phylo.draw(tree)\n",
    "# Phylo.draw(mp_tree)\n",
    "# Phylo.draw(ml_tree)\n",
    "# Phylo.draw(mad_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mp_success_rate, ml_success_rate, mad_success_rate, attempts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tree_loc = '../Tria_et_al_data/eukaryotes/ingroup/phyml/KOG3467.faa.aln.nwk'\n",
    "tree = Phylo.read(tree_loc, 'newick')\n",
    "\n",
    "# tree.root_at_midpoint()\n",
    "tree = mp_root_adhock(tree)\n",
    "Phylo.draw(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# testy = [term for term in tree.get_terminals() if\\\n",
    "#                       term.name in metazoa]\n",
    "recursive_tree_monophyly(tree.root, tree, testy, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tree.get_terminals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A weighted MaxLik implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from Bio import Phylo\n",
    "import rooting_methods, rooting_methods_weighted\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from scipy.optimize import minimize\n",
    "from scipy import stats\n",
    "\n",
    "from statsmodels.stats.weightstats import DescrStatsW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../Tree_weighting/Code/')\n",
    "import weighting_methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def update_GSC_raw(my_clade, parent_clade, weights_dict, finished):\n",
    "    \"\"\"    \n",
    "    This is pretty convoluted and could perhaps be simplified greatly with more thought. A lot of steps\n",
    "    but should be linear in O(t). The goal/purpose is to not have to re-calculate GSC weights for each \n",
    "    possible root location. Rather, calculate these values once at the starting root node and then \n",
    "    apply this function when recursively crawling the tree.\n",
    "    \n",
    "    Input/s:\n",
    "    my_clade - just a Bio.Phylo clade object\n",
    "    parent_clade - the parent of the relevant clade\n",
    "    weights_dict - the existing dictionary of clade(key):weights matrix(value) pairs\n",
    "    finished - a list of the terminals that have been completed (used for rapidly accessing\n",
    "                the downstream and upstream terminals)\n",
    "                \n",
    "    Output/s:\n",
    "    weights_dict - the updated weights_dict object with a new key:val pair added to it\n",
    "    \n",
    "    \"\"\"\n",
    "    #Get number of downstream terminals\n",
    "    ds_count = len(my_clade.get_terminals())\n",
    "    #Copy matrix from parent\n",
    "    new_array = np.array(weights_dict[parent_clade])\n",
    "    #This is the total \"weight\" to reclaim from the downstream terms and distribute to the upstreams\n",
    "    bl_to_disperse = my_clade.branch_length\n",
    "    assert np.isclose(bl_to_disperse, np.sum(new_array[len(finished):len(finished)+ds_count, -1])-\\\n",
    "                                    np.sum(new_array[len(finished):len(finished)+ds_count, -2]))\n",
    "    \n",
    "    #Get the total current weight of all upstream terms\n",
    "    to_divide = np.sum(new_array[:,-1]) - np.sum(new_array[len(finished):len(finished)+ds_count, -1])\n",
    "    #Array of values to add to the first and second set of upstream terms\n",
    "    to_add_a = new_array[:len(finished),-1]/to_divide * bl_to_disperse + new_array[:len(finished),-1]\n",
    "    to_add_b = new_array[len(finished)+ds_count:,-1]/to_divide * bl_to_disperse + new_array[len(finished)+ds_count:,-1]\n",
    "    \n",
    "    #Subtract the values from the downstream terms by rolling the values over\n",
    "    new_array[len(finished):len(finished)+ds_count] =\\\n",
    "                np.roll(new_array[len(finished):len(finished)+ds_count], 1, axis=1)\n",
    "    #And setting the first column to be zeros\n",
    "    new_array[len(finished):len(finished)+ds_count, 0] = 0\n",
    "    #Finally, append now column of zeros\n",
    "    new_array = np.append(new_array, np.zeros([len(new_array),1]), axis=1)\n",
    "    #Roll the downstream terms again\n",
    "    new_array[len(finished):len(finished)+ds_count] =\\\n",
    "                np.roll(new_array[len(finished):len(finished)+ds_count], 1, axis=1)\n",
    "    #Append the new vals for both upstream term setes\n",
    "    new_array[:len(finished),-1] = to_add_a\n",
    "    new_array[len(finished)+ds_count:,-1] = to_add_b\n",
    "    #et voila\n",
    "    weights_dict[my_clade] = new_array   \n",
    "    return weights_dict\n",
    "\n",
    "def update_depth_array_dict(my_clade, parent_clade, depths_dict, finished):\n",
    "    \"\"\"\n",
    "    This function updates the depths of each terminal in a pretty straightforward manner.\n",
    "    \n",
    "    Input/s:\n",
    "    my_clade - Bio.Phylo clade object\n",
    "    parent_clade - parent of my_clade\n",
    "    depths_dict - the exsting dictionary of depths where: clade(key):array of depths (value)\n",
    "    finished - a list of all the terminals that have been completed in the depth first search\n",
    "    \n",
    "    Output/s:\n",
    "    depths_dict - the updated depths_dict\n",
    "    ds_count - the number of terminals downstream of this particular clade\n",
    "    \n",
    "    \"\"\"\n",
    "    #First grab who is downstream of this new clade\n",
    "    ds_count = len(my_clade.get_terminals())\n",
    "    #Instantiate new array with values from parent\n",
    "    new_array = np.array(depths_dict[parent_clade])\n",
    "    #Subtract the branch length from all the downstream clades\n",
    "    new_array[len(finished):len(finished)+ds_count] -= my_clade.branch_length\n",
    "    #Add the branch length to all the upstream clades (two sets)\n",
    "    new_array[:len(finished)] += my_clade.branch_length\n",
    "    new_array[len(finished)+ds_count:] += my_clade.branch_length\n",
    "    #Update the dictionary\n",
    "    depths_dict[my_clade] = new_array\n",
    "    return depths_dict, ds_count\n",
    "\n",
    "def MinVar_root_adhock_GSC(tree, normalize_GSC=False):\n",
    "    ''' \n",
    "    This implements a rooting scheme to minimize the weighted standard deviation of the root-to-tip\n",
    "    distances for all leaves in the tree. It is unclear whether minimizing the variance of a non-normal\n",
    "    distribution would be more appropriate but this could easily be accommodated within this framework.\n",
    "    \n",
    "    Input/s:\n",
    "    tree - a Bio.Phylo tree object (in practice I like to root the tree with my basic mid-point \n",
    "                algorithm first just to ensure that the tree structure is normal-ish, i.e. bifurcating)\n",
    "    normalize_GSC - boolean of whether or not to re-scale the GSC weights in the final step\n",
    "                \n",
    "    Output/s:\n",
    "    tree - the now rooted tree object\n",
    "    function_optima - a list of all the function optimization output for each putative root tested\n",
    "    depths_dict - a dictionary of the depths for each terminal for each putative root where: \n",
    "                clade(key): array of weights for all terminals (value)\n",
    "    weights_dict - a dictionary of the weights for each terminal for each putative root where:\n",
    "                clade(key): matrix of weights for all terminals (value), final column are \n",
    "                the relevant weights but the entire matrix is necessary for rapid updating\n",
    "\n",
    "    '''\n",
    "    initial_depths = tree.root.depths()\n",
    "    #Instantiate a depths dictionary with the root node\n",
    "    depths_dict = {}\n",
    "    depths_dict[tree.root] = np.array([initial_depths[i] for i in tree.get_terminals()])\n",
    "        \n",
    "    initial_weights = weighting_methods.GSC_adhock(tree)\n",
    "    #Instantiate a weights dictionary with the root node\n",
    "    weights_array_dict = {}\n",
    "    weights_array_dict[tree.root] = np.array([initial_weights[i] for i in tree.get_terminals()])\n",
    "    #Do a lot of work! Recursively crawl the tree visiting each possible root branch\n",
    "    function_optima, depths_dict, weights_dict, finished =\\\n",
    "            recursive_crawl_MinVar(tree.root, None, [], depths_dict, weights_array_dict, [], normalize_GSC) \n",
    "    #Sort the output by the function value to find the minimum    \n",
    "    function_optima = sorted(function_optima, key=lambda x: x[1].fun)\n",
    "    #Re-root at this point \n",
    "    tree.root_with_outgroup(function_optima[0][0], outgroup_branch_length=0.)\n",
    "    assert tree.root.clades[1].branch_length == 0.\n",
    "    assert tree.root.clades[1] == function_optima[0][0]\n",
    "    #And adjust the branch lengths around this root\n",
    "    tree.root.clades[0].branch_length -= function_optima[0][1].x[0]\n",
    "    tree.root.clades[1].branch_length += function_optima[0][1].x[0]\n",
    "    return tree, function_optima, depths_dict, weights_dict\n",
    "\n",
    "def recursive_crawl_MinVar(my_clade, parent_clade, function_optima, depths_dict,\\\n",
    "                           weights_dict, finished, normalize_GSC):\n",
    "    \"\"\"\n",
    "    This is a meaty recursive function that performs the depth first search / tree crawling.\n",
    "    \n",
    "    Input/s:\n",
    "    my_clade - Bio.Phylo clade object\n",
    "    parent_clade - the parent of my_clade\n",
    "    function_optima - list of all the function_optima that I'm calculating\n",
    "    depths_dict - described in detail elsewhere\n",
    "    weights_dict - described in detail elsewhere\n",
    "    finished - list of all terminals that the depth first search has completed\n",
    "    normalize_GSC - boolean of whether or not to re-scale the GSC values\n",
    "\n",
    "    Output/s (updated versions of each of):\n",
    "    function_optima\n",
    "    depths_dict\n",
    "    weights_dict\n",
    "    finished\n",
    "    \n",
    "    \"\"\"\n",
    "    #If the node has a parent, do some calculations (this is here just to skip calculations on the root\n",
    "    if parent_clade:\n",
    "        #Update the depths dictionary\n",
    "        depths_dict, ds_count = update_depth_array_dict(my_clade, parent_clade, depths_dict, finished)\n",
    "        #Update the weights dictionary\n",
    "        weights_dict = update_GSC_raw(my_clade, parent_clade, weights_dict, finished)\n",
    "        #Minimize the variance with these values\n",
    "        res = optimize_root_loc_on_branch_MinVar(my_clade, depths_dict[my_clade],\\\n",
    "                                                 weights_dict[my_clade], ds_count, finished, normalize_GSC)\n",
    "        #Append\n",
    "        function_optima.append((my_clade, res))\n",
    "    ###Recurse (i.e. depth first search)\n",
    "    if len(my_clade.clades) == 2:\n",
    "        l_clade, r_clade = my_clade.clades\n",
    "        function_optima, depths_dict, weights_dict, finished =\\\n",
    "                recursive_crawl_MinVar(l_clade, my_clade, function_optima,\\\n",
    "                                      depths_dict, weights_dict, finished, normalize_GSC)\n",
    "        function_optima, depths_dict, weights_dict, finished =\\\n",
    "                recursive_crawl_MinVar(r_clade, my_clade, function_optima,\\\n",
    "                                      depths_dict, weights_dict, finished, normalize_GSC)\n",
    "    elif len(my_clade.clades) == 0:\n",
    "        #This is quite critical, once I reach a node with no clades I'm finished so begin to \n",
    "        #backtrack and keep track of how many I've completed\n",
    "        finished.append(my_clade)\n",
    "        return function_optima, depths_dict, weights_dict, finished\n",
    "    else:\n",
    "        print('Some big error here with the number of clades stemming from this root')\n",
    "    return function_optima, depths_dict, weights_dict, finished\n",
    "\n",
    "\n",
    "\n",
    "def optimize_root_loc_on_branch_MinVar(my_clade, depths_array, weights_array, ds_count, finished, normalize_GSC):\n",
    "    \"\"\"\n",
    "    For a given branch, ths will take the depths and weights and optimize the exact location\n",
    "    of the root for that particular branch.\n",
    "    \n",
    "    Input/s:\n",
    "    my_clade - Bio.Phylo clade object\n",
    "    depths_array - 1D numpy array of all the depths for each terminal\n",
    "    weights_array - 2D numpy array of all the weights for each terminal (last column counts)\n",
    "    ds_count - number of downstream terminals emanating from this clade\n",
    "    finished - list of all completed terminals during the depth first search\n",
    "    \n",
    "    Output/s:\n",
    "    res - the function optima (scipy.optimize object)\n",
    "    \n",
    "    \"\"\"\n",
    "    #Root-to-tip distances for all downstream terminals\n",
    "    downstream_dists = np.array(depths_array[len(finished):len(finished)+ds_count])\n",
    "    #And all upstream terminals\n",
    "    upstream_dists = np.concatenate((depths_array[:len(finished)],\\\n",
    "                                     depths_array[len(finished)+ds_count:]))\n",
    "    \n",
    "    #Weights for all downstream terminals\n",
    "    downstream_weights = np.array(weights_array[len(finished):len(finished)+ds_count, -1])\n",
    "    #And all upstream terminals\n",
    "    upstream_weights = np.concatenate((weights_array[:len(finished), -1],\\\n",
    "                                       weights_array[len(finished)+ds_count:, -1]))\n",
    "    #Also will need to know the old weights for upstream folks which should be the second to last column\n",
    "    old_upstream_weights = np.concatenate((weights_array[:len(finished), -2],\\\n",
    "                                           weights_array[len(finished)+ds_count:, -2]))\n",
    "    #Set the bounds for the optimization\n",
    "    bl_bounds = np.array([[0., my_clade.branch_length]])\n",
    "    #Valid options for method are L-BFGS-B, SLSQP and TNC\n",
    "    res = minimize(branch_scan_MinVar, np.array(np.mean(bl_bounds)),\\\n",
    "                          args=(downstream_dists, upstream_dists,\\\n",
    "                                downstream_weights, upstream_weights, old_upstream_weights, normalize_GSC),\\\n",
    "                          bounds=bl_bounds, method='SLSQP')\n",
    "    return res \n",
    "\n",
    "\n",
    "    \n",
    "def branch_scan_MinVar(modifier, ds_dists, us_dists, ds_weights, us_weights, old_us_weights, normalize_GSC=False):\n",
    "    \"\"\"\n",
    "    Should really try to make this a bit quicker/simpler if possible. All array options but a bit too\n",
    "    many I suspect.\n",
    "    \n",
    "    Input/s:\n",
    "    modifier - This is the parameter to be optimized! Essentially a float of how much to shift the\n",
    "                root left or right so as to minimize the root-to-tip variance\n",
    "    ds_dists - array of downstream root-to-tip distances\n",
    "    us_dists - array of upstream root-to-tip distances\n",
    "    ds_weights - array of downstream terminal weights\n",
    "    us_weights - array of upstream terminal weights\n",
    "    old_us_weights - array of upstream terminal weights at the last step\n",
    "    \n",
    "    Output/s:\n",
    "    dsw.std - weighted standard deviation\n",
    "    \n",
    "    \"\"\"\n",
    "    #Adjust the downstream and upstream root-to-tip distances with the modifier\n",
    "    temp_ds_dists = ds_dists + modifier\n",
    "    temp_us_dists = us_dists - modifier\n",
    "    all_dists = np.concatenate((temp_ds_dists, temp_us_dists))\n",
    "    #Get the total down stream weights\n",
    "    total_ds = np.sum(ds_weights)\n",
    "    #Divide up the added branch length (modifier) across the downstream weights\n",
    "    if total_ds != 0:\n",
    "        temp_ds_weights = ds_weights + (ds_weights/total_ds*modifier)\n",
    "    #Special case if nothing is downstream (for terminal branches)\n",
    "    else:\n",
    "        temp_ds_weights = ds_weights + modifier\n",
    "    #Get the total old upstream weights\n",
    "    total_us = np.sum(old_us_weights)\n",
    "    #Reclaim the branch length (modifier) from all the upstream weights\n",
    "    if total_us != 0:\n",
    "        temp_us_weights = us_weights - (old_us_weights/total_us*modifier)\n",
    "    #Special case for terminal branches\n",
    "    else:\n",
    "        temp_us_weights = us_weights - modifier\n",
    "    #Put all the weights together\n",
    "    all_weights = np.concatenate((temp_ds_weights, temp_us_weights))\n",
    "    \n",
    "    if normalize_GSC:\n",
    "        all_weights = all_weights/all_dists\n",
    "    #Assertion should work but can be a bit annoying for very minor differences (np.isclose) so is commented\n",
    "    #while I decide whether to deal with it or not\n",
    "    #assert np.all(all_dists - all_weights >= 0), print(all_dists,'\\n', all_weights, '\\n', all_dists-all_weights)\n",
    "    \n",
    "    #Calculate weighted variance and return\n",
    "    dsw = DescrStatsW(all_dists, all_weights)\n",
    "    return dsw.var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# tree = Phylo.read('../../Phylogenetic_couplings/Data/psicov150_aln_pdb/raw_trees/1a3aA.newick', 'newick')\n",
    "# tree = Phylo.read('/Users/adamhockenberry/Downloads/BM_Folder/paper_tree.txt', 'newick')\n",
    "tree = Phylo.read(StringIO('(((A:20, B:20):30,C:20):30, D:80)'), 'newick', rooted=False)\n",
    "# tree = Phylo.read('../Data/Tria_et_al_data/eukaryotes/ingroup/phyml/KOG0007.faa.aln.nwk', 'newick')\n",
    "# Phylo.draw(tree)\n",
    "# tree.root_with_outgroup('A', outgroup_branch_length=10e-8)\n",
    "# C = next(tree.find_elements('C'))\n",
    "# C.branch_length = 40\n",
    "# tree.root_with_outgroup('MAL')\n",
    "# noi = next(tree.find_elements('PV22'))\n",
    "# noi.branch_length += 20\n",
    "Phylo.draw(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tree = rooting_methods.mp_root_adhock(tree)\n",
    "Phylo.draw(tree)\n",
    "print([(i.name, i.branch_length) for i in tree.root.clades])\n",
    "tree, a, b, c = MinVar_root_adhock_GSC(tree, normalize_GSC=False)\n",
    "# tree, a, b, c = MinVar_root_adhock_GSC(tree, normalize_GSC=True)\n",
    "Phylo.draw(tree)\n",
    "print([(i.name, i.branch_length) for i in tree.root.clades])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tree = rooting_methods.mp_root_adhock(tree)\n",
    "Phylo.draw(tree)\n",
    "print([(i.name, i.branch_length) for i in tree.root.clades])\n",
    "tree, a, b = rooting_methods.mlfit_root_adhock(tree)\n",
    "Phylo.draw(tree)\n",
    "print([(i.name, i.branch_length) for i in tree.root.clades])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# HH weights..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import rooting_methods_general"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tree = Phylo.read('../../Phylogenetic_couplings/Data/psicov150_aln_pdb/raw_trees/1a3aA.newick', 'newick')\n",
    "fasta_loc = '../../Phylogenetic_couplings/Data/psicov150_aln_pdb/aln_fasta_max1k/1a3aA.fasta'\n",
    "# tree = Phylo.read('../Data/Tria_et_al_data/eukaryotes/ingroup/phyml/KOG0007.faa.aln.nwk', 'newick')\n",
    "# seq_records = list(SeqIO.parse('../Data/Tria_et_al_data/eukaryotes/ingroup/aln/KOG0007.faa.aln', 'fasta'))\n",
    "# Phylo.draw(tree)\n",
    "# tree.root_with_outgroup('A', outgroup_branch_length=10e-8)\n",
    "# C = next(tree.find_elements('C'))\n",
    "# C.branch_length = 40\n",
    "# tree.root_with_outgroup('MAL')\n",
    "# noi = next(tree.find_elements('PV22'))\n",
    "# noi.branch_length += 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# tree = rooting_methods.mp_root_adhock(tree)\n",
    "# # Phylo.draw(tree)\n",
    "# print([(i.name, i.branch_length) for i in tree.root.clades])\n",
    "# print([len(i.get_terminals()) for i in tree.root.clades])\n",
    "# tree, a, b = rooting_methods.MinVar_root_adhock(tree)\n",
    "# # Phylo.draw(tree)\n",
    "# print([(i.name, i.branch_length) for i in tree.root.clades])\n",
    "# print([len(i.get_terminals()) for i in tree.root.clades])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(None, 0.14757790099999971), (None, 0.0017717700000002834)]\n",
      "[338, 663]\n",
      "[(None, 0.14092611013637613), (None, 0.068305607863623885)]\n",
      "[339, 662]\n",
      "[(None, 0.074901747726326351), (None, 0.13432997027367366)]\n",
      "[662, 339]\n",
      "[(None, 0.16073029486167412), (None, 0.048501423138325887)]\n",
      "[339, 662]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adamhockenberry/Projects/Tree_rooting/Code/rooting_methods_weighted.py:287: RuntimeWarning: invalid value encountered in true_divide\n",
      "  all_weights = all_weights/all_dists\n"
     ]
    }
   ],
   "source": [
    "tree = rooting_methods.mp_root_adhock(tree)\n",
    "# Phylo.draw(tree)\n",
    "print([(i.name, i.branch_length) for i in tree.root.clades])\n",
    "print([len(i.get_terminals()) for i in tree.root.clades])\n",
    "tree, a, b, c = rooting_methods_weighted.MinVar_root_adhock_GSC(tree, normalize_GSC=False)\n",
    "print([(i.name, i.branch_length) for i in tree.root.clades])\n",
    "print([len(i.get_terminals()) for i in tree.root.clades])\n",
    "tree, a, b, c = rooting_methods_weighted.MinVar_root_adhock_GSC(tree, normalize_GSC=True)\n",
    "print([(i.name, i.branch_length) for i in tree.root.clades])\n",
    "print([len(i.get_terminals()) for i in tree.root.clades])\n",
    "tree, a, b, c = rooting_methods_weighted.MinVar_root_adhock_HH(tree, seq_records)\n",
    "print([(i.name, i.branch_length) for i in tree.root.clades])\n",
    "print([len(i.get_terminals()) for i in tree.root.clades])\n",
    "# Phylo.draw(tree)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(None, 0.14757790099999971), (None, 0.0017717700000002834)]\n",
      "[338, 663]\n",
      "[(None, 0.0030744883664457767), (None, 0.08158672963355422)]\n",
      "[542, 459]\n",
      "[(None, 0.068305623873945231), (None, 0.14092609412605478)]\n",
      "[662, 339]\n",
      "[(None, 0.074901747243664774), (None, 0.13432997075633524)]\n",
      "[662, 339]\n",
      "[(None, 0.16073029369128605), (None, 0.048501424308713965)]\n",
      "[339, 662]\n"
     ]
    }
   ],
   "source": [
    "tree = rooting_methods.mp_root_adhock(tree)\n",
    "print([(i.name, i.branch_length) for i in tree.root.clades])\n",
    "print([len(i.get_terminals()) for i in tree.root.clades])\n",
    "#\n",
    "tree, a, b, c = rooting_methods_general.MinVar_root_adhock_general(tree, weights_type=None)\n",
    "print([(i.name, i.branch_length) for i in tree.root.clades])\n",
    "print([len(i.get_terminals()) for i in tree.root.clades])\n",
    "#\n",
    "tree, a, b, c = rooting_methods_general.MinVar_root_adhock_general(tree, weights_type='GSC')\n",
    "print([(i.name, i.branch_length) for i in tree.root.clades])\n",
    "print([len(i.get_terminals()) for i in tree.root.clades])\n",
    "#\n",
    "tree, a, b, c = rooting_methods_general.MinVar_root_adhock_general(tree, weights_type='GSCn')\n",
    "print([(i.name, i.branch_length) for i in tree.root.clades])\n",
    "print([len(i.get_terminals()) for i in tree.root.clades])\n",
    "#\n",
    "tree, a, b, c = rooting_methods_general.MinVar_root_adhock_general(tree,\\\n",
    "                                                              weights_type='HH',\\\n",
    "                                                              **{'fasta_loc':fasta_loc})\n",
    "print([(i.name, i.branch_length) for i in tree.root.clades])\n",
    "print([len(i.get_terminals()) for i in tree.root.clades])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Clade(),\n",
       "        fun: 0.25019052642864814\n",
       " hess_inv: <1x1 LbfgsInvHessProduct with dtype=float64>\n",
       "      jac: array([ -1.11022302e-08])\n",
       "  message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
       "     nfev: 6\n",
       "      nit: 2\n",
       "   status: 0\n",
       "  success: True\n",
       "        x: array([ 0.04850142])),\n",
       " (Clade(),\n",
       "        fun: 0.25080570622631371\n",
       " hess_inv: <1x1 LbfgsInvHessProduct with dtype=float64>\n",
       "      jac: array([-0.04660397])\n",
       "  message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
       "     nfev: 4\n",
       "      nit: 1\n",
       "   status: 0\n",
       "  success: True\n",
       "        x: array([ 0.13432997])),\n",
       " (Clade(branch_length=0.069914052),\n",
       "        fun: 0.25226683990640703\n",
       " hess_inv: <1x1 LbfgsInvHessProduct with dtype=float64>\n",
       "      jac: array([-0.06330436])\n",
       "  message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
       "     nfev: 4\n",
       "      nit: 1\n",
       "   status: 0\n",
       "  success: True\n",
       "        x: array([ 0.06991405])),\n",
       " (Clade(),\n",
       "        fun: 0.25226683990640708\n",
       " hess_inv: <1x1 LbfgsInvHessProduct with dtype=float64>\n",
       "      jac: array([-0.02231427])\n",
       "  message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
       "     nfev: 4\n",
       "      nit: 1\n",
       "   status: 0\n",
       "  success: True\n",
       "        x: array([ 0.08466122])),\n",
       " (Clade(branch_length=0.207980837),\n",
       "        fun: 0.25862784836316977\n",
       " hess_inv: <1x1 LbfgsInvHessProduct with dtype=float64>\n",
       "      jac: array([  1.11022302e-08])\n",
       "  message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
       "     nfev: 6\n",
       "      nit: 2\n",
       "   status: 0\n",
       "  success: True\n",
       "        x: array([ 0.11142784]))]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print([(i.name, i.branch_length) for i in tree.root.clades])\n",
    "print([len(i.get_terminals()) for i in tree.root.clades])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tree = rooting_methods.mp_root_adhock(tree)\n",
    "tree, a, b = rooting_methods_weighted.mad_root_adhock(tree)\n",
    "print([(i.name, i.branch_length) for i in tree.root.clades])\n",
    "print([len(i.get_terminals()) for i in tree.root.clades])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A weighted MAD... ugh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import rooting_methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mad_root_weighted(tree):\n",
    "    for node in tree.get_terminals() + tree.get_nonterminals():\n",
    "        if node == tree.root:\n",
    "            continue\n",
    "        if node.branch_length == 0.:\n",
    "            node.branch_length = 10e-16\n",
    "    dist_df = get_lca_dist_df(tree)\n",
    "    tempy_dict = {}\n",
    "    tempy_dict[tree.root] = dist_df\n",
    "    explored, function_optima, lca_dist_df_dict = recursive_crawl_mad(tree.root, [], [], tree, tempy_dict)\n",
    "    function_optima = sorted(function_optima, key=lambda x: x[1][1])\n",
    "    tree.root_with_outgroup(function_optima[0][0], outgroup_branch_length=0.)\n",
    "    tree.root.clades[0].branch_length -= function_optima[0][1][0]\n",
    "    tree.root.clades[1].branch_length += function_optima[0][1][0]\n",
    "    RAI = function_optima[0][1][1] / function_optima[1][1][1]\n",
    "    return tree, RAI, function_optima\n",
    "\n",
    "\n",
    "def get_lca_dist_df(tree):\n",
    "    ''' \n",
    "    Where distance matrix here is subtle. I'm actually calculating the distance to LCA for an initial \n",
    "    hypothetical bifurcating root.\n",
    "    '''\n",
    "    assert tree.is_bifurcating()\n",
    "    initial = np.zeros((len(tree.get_terminals()),len(tree.get_terminals())))\n",
    "    #Call recursive function\n",
    "    recurse, finished_list = recursive_clade(initial, tree.root, finished=[])\n",
    "    final = recurse - recurse.diagonal()\n",
    "    term_names = [i.name for i in tree.get_terminals()]\n",
    "    final_df = pd.DataFrame(final, index=term_names, columns=term_names)\n",
    "    return final_df\n",
    "\n",
    "def recursive_clade(vcv_matrix, initial_clade, finished=[]):\n",
    "    ''' \n",
    "    This is kind of complicated looking but it should scale linearly with tree size\n",
    "    '''\n",
    "    if len(initial_clade) == 2:\n",
    "        #Add branch length to relevant cells in matrix and move down the left side\n",
    "        if not set(initial_clade[0].get_terminals()).issubset(set(finished)):\n",
    "            clade = initial_clade[0]\n",
    "            clade_term_n = len(clade.get_terminals())\n",
    "            finished_n = len(finished)\n",
    "            vcv_matrix[finished_n:finished_n+clade_term_n, finished_n:finished_n+clade_term_n] += clade.branch_length\n",
    "            vcv_matrix, finished = recursive_clade(vcv_matrix, clade, finished)\n",
    "        #Add branch length to relevant cells in matrix and move down the right side\n",
    "        if not set(initial_clade[1].get_terminals()).issubset(set(finished)):\n",
    "            clade = initial_clade[1]\n",
    "            clade_term_n = len(clade.get_terminals())\n",
    "            finished_n = len(finished)\n",
    "            vcv_matrix[finished_n:finished_n+clade_term_n, finished_n:finished_n+clade_term_n] += clade.branch_length\n",
    "            vcv_matrix, finished = recursive_clade(vcv_matrix, clade, finished)\n",
    "    elif len(initial_clade) == 0:\n",
    "        finished.append(initial_clade)\n",
    "    else:\n",
    "        print(\"ERROR: APPEARS TO BE A NON-BINARY TREE. MATRIX GENERATION WILL PROBABLY FAIL\")\n",
    "    return vcv_matrix, finished\n",
    "\n",
    "def recursive_crawl_mad(hypothetical_root, explored, function_optima, tree, lca_dist_df_dict):\n",
    "    if len(hypothetical_root.clades) == 2:\n",
    "        l_clade, r_clade = hypothetical_root.clades\n",
    "        ###Recurse on l clade\n",
    "        lca_dist_df_dict, my_terms, other_terms = update_lca_dist_df_dict(lca_dist_df_dict, l_clade, hypothetical_root, tree)\n",
    "        res = mad_from_df(l_clade, my_terms, other_terms, lca_dist_df_dict[l_clade])\n",
    "        function_optima.append((l_clade, res))\n",
    "        explored, function_optima, lca_dist_df_dict = recursive_crawl_mad(l_clade, explored, function_optima, tree, lca_dist_df_dict)\n",
    "        ###Recurse on r clade\n",
    "        lca_dist_df_dict, my_terms, other_terms = update_lca_dist_df_dict(lca_dist_df_dict, r_clade, hypothetical_root, tree)\n",
    "        res = mad_from_df(r_clade, my_terms, other_terms, lca_dist_df_dict[r_clade])\n",
    "        function_optima.append((r_clade, res))\n",
    "        explored, function_optima, lca_dist_df_dict = recursive_crawl_mad(r_clade, explored, function_optima, tree, lca_dist_df_dict)\n",
    "    elif len(hypothetical_root.clades) == 0:\n",
    "        explored.append(hypothetical_root)\n",
    "        return explored, function_optima, lca_dist_df_dict\n",
    "    else:\n",
    "        print('non binary tree...?')\n",
    "    explored.append(hypothetical_root)\n",
    "    return explored, function_optima, lca_dist_df_dict\n",
    "\n",
    "def update_lca_dist_df_dict(lca_dist_df_dict, my_clade, parent, my_tree):\n",
    "    bl = my_clade.branch_length\n",
    "    downstream_terms = [i.name for i in my_clade.get_terminals()]\n",
    "    upstream_terms = list(set([i.name for i in my_tree.get_terminals()]) - set(downstream_terms))\n",
    "    lca_dist_df = lca_dist_df_dict[parent].copy(deep=True)\n",
    "    lca_dist_df.loc[downstream_terms,upstream_terms] -= bl\n",
    "    lca_dist_df.loc[upstream_terms,downstream_terms] += bl\n",
    "    lca_dist_df_dict[my_clade] = lca_dist_df\n",
    "    return lca_dist_df_dict, downstream_terms, upstream_terms\n",
    "\n",
    "def mad_from_df(my_clade, my_terms, other_terms, lca_dist_df):\n",
    "    '''\n",
    "    Need to document this\n",
    "    '''\n",
    "    print('###########')\n",
    "    my_df = lca_dist_df.loc[my_terms, my_terms]\n",
    "    other_df = lca_dist_df.loc[other_terms, other_terms]\n",
    "    my_df_trans = my_df.T\n",
    "    other_df_trans = other_df.T\n",
    "    print(my_df_trans)\n",
    "    print(other_df_trans)\n",
    "    #Dealing with same side pairs\n",
    "    ss_a_dists = np.abs(np.concatenate((my_df.values[np.triu_indices(len(my_terms), k = 1)],\\\n",
    "                                other_df.values[np.triu_indices(len(other_terms), k = 1)])))\n",
    "    ss_b_dists = np.abs(np.concatenate((my_df_trans.values[np.triu_indices(len(my_terms), k = 1)],\\\n",
    "                                other_df_trans.values[np.triu_indices(len(other_terms), k = 1)])))\n",
    "    print(ss_a_dists, ss_b_dists)\n",
    "    ss_total_dists = ss_a_dists + ss_b_dists\n",
    "    ss_devs = np.abs(((2*ss_a_dists)/ss_total_dists)-1)\n",
    "    print(ss_devs)\n",
    "    #Dealing with different side pairs\n",
    "    ds_a_dists = lca_dist_df.loc[my_terms, other_terms].values.flatten(order='C')\n",
    "    ds_b_dists = lca_dist_df.loc[other_terms, my_terms].values.flatten(order='F')\n",
    "    ds_total_dists = ds_a_dists + ds_b_dists\n",
    "\n",
    "    ###Using the analytical solution to \"rho\" parameter as outlined in the MAD paper\n",
    "    total_bl = my_clade.branch_length\n",
    "    if total_bl > 0.:\n",
    "        rho = np.sum((ds_total_dists-(2*ds_a_dists))*ds_total_dists**-2)/(2*total_bl*np.sum(ds_total_dists**-2))\n",
    "        modifier = total_bl*rho\n",
    "        modifier = min(max(0, modifier), total_bl)\n",
    "    else:\n",
    "        modifier = 0.\n",
    "\n",
    "    ###Rescale the distances with the optimized modifier\n",
    "    ds_a_dists = ds_a_dists + modifier\n",
    "    ds_b_dists = ds_b_dists - modifier\n",
    "    ds_total_dists = ds_a_dists + ds_b_dists\n",
    "    ###Calculate their deviations\n",
    "    ds_devs = np.abs(((2*ds_a_dists)/ds_total_dists)-1)\n",
    "\n",
    "    ###Concatenate them with the pre-computed same side deviations (ss_devs)\n",
    "    all_devs = np.concatenate((ss_devs, ds_devs))\n",
    "    ###And compute final MAD score\n",
    "    all_devs = all_devs**2\n",
    "    dev_score = np.mean(all_devs)\n",
    "    dev_score = dev_score**0.5\n",
    "    return (modifier, dev_score)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# tree = Phylo.read('../../Phylogenetic_couplings/Data/psicov150_aln_pdb/raw_trees/1a3aA.newick', 'newick')\n",
    "# tree = Phylo.read('/Users/adamhockenberry/Downloads/BM_Folder/paper_tree.txt', 'newick')\n",
    "tree = Phylo.read(StringIO('(((A:20, B:20):30,C:50):30, D:80)'), 'newick', rooted=False)\n",
    "# tree = Phylo.read('../../Tree_rooting/Tria_et_al_data/eukaryotes/ingroup/phyml/KOG0007.faa.aln.nwk', 'newick')\n",
    "# Phylo.draw(tree)\n",
    "# tree.root_with_outgroup('A', outgroup_branch_length=10e-8)\n",
    "# C = next(tree.find_elements('C'))\n",
    "# C.branch_length = 40\n",
    "# tree.root_with_outgroup('MAL')\n",
    "# noi = next(tree.find_elements('PV22'))\n",
    "# noi.branch_length += 20\n",
    "# Phylo.draw(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tree = rooting_methods.mp_root_adhock(tree)\n",
    "Phylo.draw(tree)\n",
    "print([(i.name, i.branch_length) for i in tree.root.clades])\n",
    "tree, a, b = mad_root_weighted(tree)\n",
    "# Phylo.draw(tree)\n",
    "# print([(i.name, i.branch_length) for i in tree.root.clades])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tree.depths()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i, terminal_a in enumerate(tree.get_terminals()):\n",
    "    for j, terminal_b in enumerate(tree.get_terminals()):\n",
    "        if j >= i:\n",
    "            continue\n",
    "        path = [terminal_a] + tree.trace(terminal_a, terminal_b)\n",
    "        ca = tree.common_ancestor(terminal_a, terminal_b)\n",
    "        if ca.branch_length:\n",
    "            path_len = np.sum([edge.branch_length for edge in path if edge.branch_length]) - ca.branch_length\n",
    "        else: \n",
    "            path_len = np.sum([edge.branch_length for edge in path if edge.branch_length])\n",
    "        print(terminal_a, terminal_b, path_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testy = get_lca_dist_df(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_paths = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(index=['AB', 'AC', 'AD', 'BC', 'BD', 'CD'],\\\n",
    "                  columns=['AB', 'AC', 'AD', 'BC', 'BD', 'CD'], dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in df.index:\n",
    "    df.set_value(i, i, 1.)\n",
    "pairs = [['AB', 'AC', 0.1],\\\n",
    "         ['AB', 'AD', 0.0625],\\\n",
    "         ['AB', 'BC', 0.1],\\\n",
    "         ['AB', 'BD', 0.0625],\\\n",
    "         ['AB', 'CD', 0.],\\\n",
    "         ['AC', 'AD', 0.15625],\\\n",
    "         ['AC', 'BC', 0.64],\\\n",
    "         ['AC', 'BD', 0.05625],\\\n",
    "         ['AC', 'CD', 0.15625],\\\n",
    "         ['AD', 'BC', 0.05625],\\\n",
    "         ['AD', 'BD', 0.765625],\\\n",
    "         ['AD', 'CD', 0.47265625],\\\n",
    "         ['BC', 'BD', 0.15625],\\\n",
    "         ['BC', 'CD', 0.15625],\\\n",
    "         ['BD', 'CD', 0.47265625]]\n",
    "for i,j,k in pairs:\n",
    "    df.set_value(i, j, k)\n",
    "    df.set_value(j, i, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mat = df.values\n",
    "inv_mat = np.linalg.inv(mat)\n",
    "rowsums = np.sum(inv_mat, axis=1)\n",
    "weights = rowsums/inv_mat.sum()\n",
    "weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.matshow(inv_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(np.array([40, 100, 160, 50, 160, 160])/230)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Toy example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(index=['AB', 'AC', 'BC'],\\\n",
    "                  columns=['AB', 'AC', 'BC'], dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in df.index:\n",
    "    df.set_value(i, i, 1.)\n",
    "pairs = [['AB', 'AC', (20**2)/(40*100)],\\\n",
    "         ['AB', 'BC', (20**2)/(40*100)],\\\n",
    "         ['AC', 'BC', (80**2)/(100*100)]]\n",
    "for i,j,k in pairs:\n",
    "    df.set_value(i, j, k)\n",
    "    df.set_value(j, i, k)\n",
    "\n",
    "mat = df.values\n",
    "inv_mat = np.linalg.inv(mat)\n",
    "rowsums = np.sum(inv_mat, axis=1)\n",
    "weights = rowsums/inv_mat.sum()\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in df.index:\n",
    "    df.set_value(i, i, 1.)\n",
    "pairs = [['AB', 'AC', (5**2)/(10*100)],\\\n",
    "         ['AB', 'BC', (5**2)/(10*100)],\\\n",
    "         ['AC', 'BC', (95**2)/(100*100)]]\n",
    "for i,j,k in pairs:\n",
    "    df.set_value(i, j, k)\n",
    "    df.set_value(j, i, k)\n",
    "\n",
    "mat = df.values\n",
    "inv_mat = np.linalg.inv(mat)\n",
    "rowsums = np.sum(inv_mat, axis=1)\n",
    "weights = rowsums/inv_mat.sum()\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "20**2 / 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "1/((1/50.) + (1/((50*130)/180)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "1/((1/130.)+(1/20)+(1/((50*130)/180)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "20.967741935483872 / (20.967741935483872+11.711711711711711+11.711711711711711)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "112.5/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mat = [[50, 30, 0],\\\n",
    "       [30, 50, 0],\\\n",
    "       [0, 0, 50]]\n",
    "inv_mat = np.linalg.inv(mat)\n",
    "rowsums = np.sum(inv_mat, axis=1)\n",
    "weights = rowsums/inv_mat.sum()\n",
    "weights, np.sum(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(36.111111+50)/(36.111111+130+40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "50/102.6315"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mat = [[50, 45, 0],\\\n",
    "       [45, 50, 0],\\\n",
    "       [0, 0, 50]]\n",
    "inv_mat = np.linalg.inv(mat)\n",
    "rowsums = np.sum(inv_mat, axis=1)\n",
    "weights = rowsums/inv_mat.sum()\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mat = [[80, 60, 30, 0],\\\n",
    "       [60, 80, 30, 0],\\\n",
    "       [30, 30, 80, 0],\\\n",
    "       [0, 0, 0, 80]]\n",
    "inv_mat = np.linalg.inv(mat)\n",
    "rowsums = np.sum(inv_mat, axis=1)\n",
    "weights = rowsums/inv_mat.sum()\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "20/(110/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "40/(200/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dicty = defaultdict(lambda: [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dicty[1].append(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dicty[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dicty[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dumb_fxn(**kwargs):\n",
    "    print(kwargs)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'blah': 5}\n"
     ]
    }
   ],
   "source": [
    "dumb_fxn(**{'blah':5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1001"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tree.get_terminals())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEKCAYAAAAfGVI8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/57vkApmH3PIAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x122d028d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# tree = Phylo.read('../../Phylogenetic_couplings/Data/psicov150_aln_pdb/raw_trees/1a3aA.newick', 'newick')\n",
    "# tree = Phylo.read('/Users/adamhockenberry/Downloads/BM_Folder/paper_tree.txt', 'newick')\n",
    "tree = Phylo.read(StringIO('(((A:20, B:20):30,C:20):30, D:80)'), 'newick', rooted=False)\n",
    "# tree = Phylo.read('../Data/Tria_et_al_data/eukaryotes/ingroup/phyml/KOG0007.faa.aln.nwk', 'newick')\n",
    "# Phylo.draw(tree)\n",
    "# tree.root_with_outgroup('A', outgroup_branch_length=10e-8)\n",
    "# C = next(tree.find_elements('C'))\n",
    "# C.branch_length = 40\n",
    "# tree.root_with_outgroup('MAL')\n",
    "# noi = next(tree.find_elements('PV22'))\n",
    "# noi.branch_length += 20\n",
    "Phylo.draw(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(((A:20.00000,B:20.00000):30.00000,C:20.00000):30.00000,D:80.00000):0.00000;\\n'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.format('newick')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from io import StringIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "unit_tree = Phylo.read(StringIO(tree.format('newick')), 'newick')\n",
    "for node in unit_tree.get_terminals() + unit_tree.get_nonterminals():\n",
    "    if node.branch_length:\n",
    "        node.branch_length = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(((A:20.00000,B:20.00000):30.00000,C:20.00000):30.00000,D:80.00000):0.00000;\\n'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unit_tree.format('newick')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for node in unit_tree.get_terminals() + unit_tree.get_nonterminals():\n",
    "    if node.branch_length:\n",
    "        node.branch_length = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(((A:1.00000,B:1.00000):1.00000,C:1.00000):1.00000,D:1.00000):0.00000;\\n'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unit_tree.format('newick')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
